# üß¨ News Collector System

## Sistema Automatizado de Recopilaci√≥n y Scoring de Noticias Cient√≠ficas

[![CI Status](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/noticiencias/<CI_BADGE_GIST_ID>/raw/ci-badge.json)](https://github.com/noticiencias/noticiencias_news_collector/actions/workflows/ci.yml?query=branch%3Amain+event%3Apush)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: MVP](https://img.shields.io/badge/Status-MVP-green.svg)]()

> ‚ÑπÔ∏è Sustituye `<CI_BADGE_GIST_ID>` por el identificador real del gist configurado en el secreto `CI_BADGE_GIST_ID` y crea el secreto `CI_BADGE_PAT` con un token que tenga permisos `repo` y `gist`.

Un sistema inteligente que recopila autom√°ticamente noticias cient√≠ficas de las mejores fuentes del mundo, las eval√∫a mediante un algoritmo de scoring multidimensional, y selecciona las m√°s importantes para tu audiencia.

---

## üéØ ¬øQu√© hace este sistema?

Imagina tener un asistente de investigaci√≥n s√∫per inteligente que:

- **üîç Explora** las mejores fuentes cient√≠ficas del mundo (Nature, Science, MIT News, etc.)
- **üß† Eval√∫a** cada art√≠culo seg√∫n credibilidad, recencia, calidad y potencial de engagement
- **‚≠ê Selecciona** autom√°ticamente los descubrimientos m√°s importantes
- **üìä Proporciona** scores transparentes y explicaciones detalladas
- **üöÄ Funciona** 24/7 sin supervisi√≥n

Eso es exactamente lo que hace este sistema.

---

## üèóÔ∏è Arquitectura de Referencia

```mermaid
graph TD
    Scheduler[Scheduler] --> Collectors[Collectors]
    Collectors --> Parsers[Parser & Normalizer]
    Parsers --> Dedupe[Canonicalizaci√≥n & Dedupe]
    Dedupe --> Enrichment[Enrichment]
    Enrichment --> Scoring[Scoring]
    Scoring --> Reranker[Reranker]
    Reranker --> Storage[Storage]
    Storage --> Serving[Serving]
    Storage --> Monitoring[Monitoring]
```

- Contratos clave: [Event Envelope v1](AGENTS.md#11-event-envelope-v1), [Article Entity v2](AGENTS.md#12-article-entity-v2), [Cluster Record v1](AGENTS.md#13-cluster-record-v1), [Score Explanation v1](AGENTS.md#14-score-explanation-v1).
- Cada componente publica logs estructurados (`trace_id`, `source_id`, `article_id`) descritos en el [Runbook Operacional](docs/runbook.md).
- Para flujos de resoluci√≥n de incidentes espec√≠ficos del colector revisa el [Collector Runbook](docs/collector_runbook.md).

## ‚ú® Caracter√≠sticas Principales

### ü§ñ Recolecci√≥n Inteligente
- **Fuentes Premium**: Nature, Science, Cell, NEJM, MIT News, Stanford News, NASA, y m√°s
- **M√∫ltiples Formatos**: RSS, Atom, feeds institucionales
- **Respeto por Servidores**: Rate limiting inteligente, manejo de errores robusto
  - Feeds comunitarios (ej. r/science) se consultan como m√°ximo una vez por minuto para respetar el rate limit de Reddit (intervalos >=30s y user-agent dedicado)
  - Configuraciones como `min_delay_seconds` por fuente y `RATE_LIMITING_CONFIG["domain_overrides"]` aseguran tiempos de espera adicionales cuando un host lo exige (ej. arXiv = 20s, Reddit = 30s)
- **Caching Condicional**: Persistimos `ETag` y `Last-Modified` por fuente para enviar `If-None-Match`/`If-Modified-Since`, reduciendo ancho de banda y evitando descargas innecesarias cuando no hay contenido nuevo.
- **Modo As√≠ncrono Opcional**: al activar `ASYNC_ENABLED=true` el colector usa `httpx.AsyncClient` y un `asyncio.Semaphore` controlado por `MAX_CONCURRENT_REQUESTS` para paralelizar dominios distintos sin saltarse `robots.txt`, deduplicaci√≥n ni l√≠mites por dominio.
- **Deduplicaci√≥n**: Detecci√≥n autom√°tica de contenido duplicado

### üß† Scoring Multidimensional
- **Credibilidad de Fuente** (30%): pondera el prestigio de la fuente.
- **Freshness Decay** (25%): aplica una ca√≠da exponencial seg√∫n horas desde la publicaci√≥n.
- **Calidad de Contenido** (25%): valora densidad/riqueza del art√≠culo y entidades detectadas.
- **Engagement Potencial** (20%): combina sentimiento y se√±ales de interacci√≥n.
- **Penalizaci√≥n de Diversidad**: resta puntos a duplicados del mismo cluster para priorizar variedad.

Cada art√≠culo incluye un payload de "why ranked" con contribuciones por feature, pesos y penalizaciones.

### üîÅ Reranker Determin√≠stico
- Limita el porcentaje de art√≠culos por fuente y por tema en el top-K.
- Reordena con desempate: score ‚Üí recencia ‚Üí fuente ‚Üí random seed.
- Configurable mediante `SOURCE_CAP_PERCENTAGE`, `TOPIC_CAP_PERCENTAGE`, `RERANKER_SEED`.

### üìä Transparencia Total
- Cada score se explica completamente
- Desglose detallado por componente
- Trazabilidad de decisiones
- M√©tricas de performance en tiempo real

### üìà Evaluaci√≥n Offline
- `python scripts/evaluate_ranking.py` ‚Üí NDCG@5, Precision@5, MRR sobre un dev set.
- `python scripts/reranker_distribution.py` ‚Üí distribuci√≥n de fuentes/temas antes vs. despu√©s del reranker.
- `python scripts/enrichment_sanity.py` ‚Üí sanity check de enriquecimiento (lenguaje, sentimiento, t√≥picos, entidades).
- `python scripts/weekly_quality_report.py tests/data/monitoring/outage_replay.json` ‚Üí genera reporte semanal en formato com√∫n.
- `python scripts/replay_outage.py tests/data/monitoring/outage_replay.json` ‚Üí replay de outage hist√≥rico con alertas canario.
- Ver especificaci√≥n del formato en `docs/common_output_format.md`.

### üõ†Ô∏è Facilidad de Uso
- **Instalaci√≥n Simple**: Una l√≠nea de comando
- **Configuraci√≥n Flexible**: Variables de entorno
- **M√∫ltiples Interfaces**: CLI, API program√°tica
- **Logging Comprehensivo**: Observabilidad completa (estructura y campos obligatorios en el [Runbook Operacional](docs/runbook.md))
- **Runbooks Accionables**: Gu√≠as paso a paso en [docs/runbook.md](docs/runbook.md) y [docs/collector_runbook.md](docs/collector_runbook.md)

---

## üöÄ Instalaci√≥n R√°pida

### Prerrequisitos
- Python 3.10 o superior (probado en 3.13)
- Git

### 1. Clonar el Repositorio
> ‚ÑπÔ∏è El repositorio es privado. Aseg√∫rate de tener acceso autorizado (SSH o token personal) antes de clonar.

```bash
# Usando SSH (recomendado)
git clone git@github.com:noticiencias/noticiencias_news_collector.git
cd noticiencias_news_collector

# Usando HTTPS + token personal
git clone https://github.com/noticiencias/noticiencias_news_collector.git
cd noticiencias_news_collector
```

### 2. Crear y activar entorno virtual (recomendado)
```bash
# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

> üí° Si prefieres automatizar estos pasos, el comando `make bootstrap` crea el entorno virtual e instala cada dependencia por ti.

### 3. Instalar Dependencias (Makefile recomendado)
```bash
make bootstrap
```

> üí° ¬øActualizaste `requirements.txt`? Regenera el lock ejecutando:
> ```bash
> python -m piptools compile --generate-hashes --output-file requirements.lock requirements.txt
> ```

### 4. Verificar Instalaci√≥n
```bash
make test
```

### 5. Configurar Entorno
El proyecto usa [`python-dotenv`](https://github.com/theskumar/python-dotenv) para cargar variables desde un archivo `.env`.
El template [`.env.example`](.env.example) documenta todos los par√°metros admitidos y agrupa las opciones por secciones
(`runtime`, `database`, `collection`, `scoring`, etc.). Copia el archivo y ajusta los valores seg√∫n tu escenario:

```bash
cp .env.example .env
# Edita .env para habilitar Postgres, ajustar rate limits o personalizar el scoring.
```

> ‚ÑπÔ∏è Si vas a usar PostgreSQL, descomenta el bloque `# Database configuration` y reemplaza las credenciales. Para entornos de
> operaci√≥n consulta tambi√©n las secciones `# Operational scripts` y `# Logging`.

### üñ•Ô∏è Editor de Configuraci√≥n

La herramienta `tools.config_editor` permite inspeccionar y modificar cualquier archivo de configuraci√≥n soportado
(`.env`, YAML, JSON, TOML o m√≥dulos `config.py`) desde una interfaz Tkinter o en modo headless con las mismas validaciones.

- **GUI r√°pida**: `make config-gui CONFIG_PATH=$(PWD)` abre la ventana y recuerda tama√±o/posici√≥n.
- **Headless para CI**: `make config-set KEY="ingest.timeout=45" PROFILE=dev EXTRA="debug=false"` actualiza varios valores sin GUI.
- **CLI directo**:

  ```bash
  python -m tools.config_editor --config config --profile dev
  python -m tools.config_editor --config config --set ingest.timeout=30 --profile prod
  ```

> üõ°Ô∏è Cada guardado valida los tipos, escribe de forma at√≥mica y crea un respaldo con timestamp en `./backups/` sin exponer secretos en logs (`logs/config_editor.log`).

### 6. Ejecutar Primera Recolecci√≥n
```bash
python run_collector.py --dry-run
```

Si usas VS Code, selecciona el int√©rprete del entorno virtual:
```
.venv\Scripts\python.exe  (Windows)
.venv/bin/python           (macOS/Linux)
```

¬°Con eso basta! El sistema ejecutar√° una simulaci√≥n y te mostrar√° c√≥mo funcionar√≠a.

---

## üéÆ Uso B√°sico

### Recolecci√≥n Simple
```bash
# Recolecci√≥n completa de todas las fuentes
python run_collector.py

# Modo simulaci√≥n (no guarda datos)
python run_collector.py --dry-run

# Fuentes espec√≠ficas
python run_collector.py --sources nature science mit_news

# Modo silencioso
python run_collector.py --quiet
```

### Ver Fuentes Disponibles
```bash
python run_collector.py --list-sources
```

### Verificar Dependencias
```bash
python run_collector.py --check-deps
```

### Healthcheck Operativo
```bash
python run_collector.py --healthcheck
```
- Verifica conectividad con la base de datos, backlog en la cola de art√≠culos pendientes y la frescura de la √∫ltima ingesta.
- Consulta el runbook completo en [`docs/runbook.md`](docs/runbook.md) para flujos de diagn√≥stico y resoluci√≥n cuando el healthcheck falle.

### Ejecutar en contenedor (experimental)
```bash
# Construye la imagen con la etiqueta sugerida (fecha UTC + short SHA)
export TAG="$(date -u +%Y%m%d).$(git rev-parse --short HEAD)"
docker build -t noticiencias/collector:${TAG} .

# Ejecuta la imagen con la configuraci√≥n incluida y realiza un dry-run
docker run --rm \
    noticiencias/collector:${TAG} --dry-run
```

El workflow `Release` empaqueta autom√°ticamente la imagen `noticiencias/collector:<fecha>.<sha>` como artefacto. Cada ejecuci√≥n adjunta un archivo `image-run.md` con instrucciones para cargarla mediante `docker load` y repetir los pasos de bootstrap dentro del contenedor.

---

## üìö Fuentes Configuradas

### üèÜ Journals de √âlite
- **Nature** - La revista cient√≠fica m√°s prestigiosa del mundo
- **Science** - Revista insignia de la AAAS
- **Cell** - L√≠der en biolog√≠a celular y molecular  
- **NEJM** - La biblia de la medicina cl√≠nica

### üéì Fuentes Institucionales
- **MIT News** - Instituto de Tecnolog√≠a de Massachusetts
- **Stanford News** - Universidad de Stanford
- **NASA News** - Agencia Espacial NASA
- **NIH News** - Instituto Nacional de Salud

### üì∞ Medios Especializados
- **Scientific American** - Divulgaci√≥n cient√≠fica de calidad
- **New Scientist** - Ciencia emergente y tendencias
- **Ars Technica** - Tecnolog√≠a y ciencia aplicada
- **Phys.org** - Agregador de noticias universitarias

### üìë Repositorios de Preprints
- **arXiv** - Preprints de IA y Machine Learning
- **bioRxiv** - Preprints de biolog√≠a y ciencias de la vida

### üåê Fuentes Comunitarias
- **r/science** - Subreddit moderado de divulgaci√≥n cient√≠fica (consulta limitada para respetar a Reddit)

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno Principales

```bash
# Colector RSS (sincr√≥nico por defecto)
ASYNC_ENABLED=false               # true ‚Üí usa AsyncRSSCollector
MAX_CONCURRENT_REQUESTS=8         # techo global de corrutinas

# Frecuencia de recolecci√≥n (horas)
COLLECTION_INTERVAL=6

# N√∫mero de mejores art√≠culos diarios
DAILY_TOP_COUNT=10

# Score m√≠nimo para incluir art√≠culos
MINIMUM_SCORE=0.3

# Scoring (modo por defecto = advanced)
SCORING_MODE=advanced               # basic / advanced

# Pesos legacy (modo basic)
WEIGHT_SOURCE=0.25
WEIGHT_RECENCY=0.20
WEIGHT_CONTENT=0.25
WEIGHT_ENGAGEMENT=0.30

# Pesos modo advanced (deben sumar 1.0)
FEATURE_WEIGHT_SOURCE=0.30
FEATURE_WEIGHT_FRESHNESS=0.25
FEATURE_WEIGHT_CONTENT=0.25
FEATURE_WEIGHT_ENGAGEMENT=0.20

# Freshness decay
FRESHNESS_HALF_LIFE_HOURS=18
FRESHNESS_MAX_DECAY_HOURS=168

# Diversidad
DIVERSITY_PENALTY_WEIGHT=0.15
DIVERSITY_MAX_PENALTY=0.3

# Heur√≠sticas de calidad de contenido
SCORING_TITLE_LENGTH_DIVISOR=120
SCORING_SUMMARY_LENGTH_DIVISOR=400
SCORING_ENTITY_TARGET_COUNT=5
SCORING_CONTENT_WEIGHT_TITLE=0.4
SCORING_CONTENT_WEIGHT_SUMMARY=0.4
SCORING_CONTENT_WEIGHT_ENTITY=0.2

# Heur√≠sticas de engagement
SCORING_SENTIMENT_POSITIVE=0.7
SCORING_SENTIMENT_NEUTRAL=0.5
SCORING_SENTIMENT_NEGATIVE=0.6
SCORING_SENTIMENT_FALLBACK=0.5
SCORING_WORD_COUNT_DIVISOR=800
SCORING_ENGAGEMENT_EXTERNAL_WEIGHT=0.6
SCORING_ENGAGEMENT_LENGTH_WEIGHT=0.4

# Concurrencia de scoring
SCORING_WORKERS=4

# Reranker determin√≠stico
SOURCE_CAP_PERCENTAGE=0.5
TOPIC_CAP_PERCENTAGE=0.6
RERANKER_SEED=1337
```

### Modo As√≠ncrono del Colector

Activa `ASYNC_ENABLED=true` cuando:

- Necesitas abarcar muchas fuentes I/O-bound en la misma ventana de recolecci√≥n.
- Los tiempos de respuesta promedio de las fuentes son altos (>2‚ÄØs) y quieres mejorar throughput sin abrir m√∫ltiples procesos.
- Ya validaste en `staging` que los hosts respetan `If-None-Match`/`If-Modified-Since` (el modo async mantiene los mismos validadores y dedupe).

Recomendaciones:

- Ajusta `MAX_CONCURRENT_REQUESTS` seg√∫n la capacidad de salida del entorno (8‚Äì12 suele funcionar; valores mayores pueden saturar DNS o proxies).
- El colector sigue aplicando `robots.txt` y `min_delay_seconds` por dominio mediante locks; revisa Grafana ‚Üí panel "collector wait time" tras el despliegue.
- Mant√©n `RATE_LIMITING_CONFIG["domain_overrides"]` actualizado: la ejecuci√≥n as√≠ncrona respeta esos l√≠mites pero incrementar√° la presi√≥n si hay muchos dominios sin override.

### Personalizar Pesos de Scoring

Para el modo *advanced* ajusta los feature weights:

```bash
# Breaking news (m√°s frescura)
FEATURE_WEIGHT_FRESHNESS=0.40
FEATURE_WEIGHT_SOURCE=0.25
FEATURE_WEIGHT_CONTENT=0.20
FEATURE_WEIGHT_ENGAGEMENT=0.15

# Publicaciones acad√©micas (mayor credibilidad)
FEATURE_WEIGHT_SOURCE=0.45
FEATURE_WEIGHT_CONTENT=0.30
FEATURE_WEIGHT_FRESHNESS=0.15
FEATURE_WEIGHT_ENGAGEMENT=0.10
```

¬øNecesitas volver al algoritmo previo? Configura `SCORING_MODE=basic`.

### Ajustar heur√≠sticas sin romper el scoring

El modo *advanced* expone controles finos para ajustar la sensibilidad del algoritmo sin introducir efectos secundarios inesperados:

- **Divisores de longitud (`SCORING_TITLE_LENGTH_DIVISOR`, `SCORING_SUMMARY_LENGTH_DIVISOR`, `SCORING_WORD_COUNT_DIVISOR`)**: definen cu√°ntos caracteres/palabras consideramos "suficientes" antes de dar puntuaci√≥n m√°xima. √ötiles para adaptar el sistema a res√∫menes m√°s cortos o notas largas.
- **Peso de entidades (`SCORING_ENTITY_TARGET_COUNT`, `SCORING_CONTENT_WEIGHT_*`)**: controla cu√°nta relevancia damos a art√≠culos con entidades enriquecidas. Mant√©n la suma de los pesos en `1.0` para conservar una escala estable.
- **Sentimiento y engagement (`SCORING_SENTIMENT_*`, `SCORING_ENGAGEMENT_*`)**: permite reforzar o suavizar la se√±al emocional del contenido. Todos los valores se validan para permanecer en el rango `[0, 1]` y los pesos deben sumar `1.0` para evitar sesgos.

El scorer valida estos par√°metros al arrancar y levantar√° un `ValueError` si detecta divisores no positivos, pesos fuera de rango o sumas incorrectas. As√≠ evitamos despliegues con configuraciones inconsistentes.

---

## üîß Uso Program√°tico

### API Python

```python
from main import create_system

# Crear e inicializar sistema
system = create_system()
system.initialize()

# Ejecutar recolecci√≥n
results = system.run_collection_cycle()

# Obtener mejores art√≠culos
top_articles = system.get_top_articles(limit=10)

# Ver estad√≠sticas
stats = system.get_system_statistics()
```

### Configuraci√≥n Personalizada

```python
# Override de configuraci√≥n
config_override = {
    'scoring_weights': {
        'source_credibility': 0.40,
        'recency': 0.30,
        'content_quality': 0.20,
        'engagement_potential': 0.10
    }
}

system = create_system(config_override)
```

---

## üìä Entendiendo los Scores

### Componentes del Score

Cada art√≠culo recibe un score de 0.0 a 1.0 basado en cuatro dimensiones:

#### üèõÔ∏è Credibilidad de Fuente (25%)
- **1.0**: Nature, Science, NEJM
- **0.8**: Journals de alta calidad
- **0.6**: Medios especializados confiables
- **0.4**: Fuentes acad√©micas est√°ndar

#### ‚è∞ Recencia (20%)
- **1.0**: Publicado en la √∫ltima hora
- **0.9**: Publicado hoy
- **0.7**: Publicado esta semana
- **0.3**: Publicado este mes

#### üìù Calidad de Contenido (25%)
- Longitud apropiada del texto
- Presencia de terminolog√≠a cient√≠fica
- Estructura del t√≠tulo
- Diversidad de vocabulario

#### üî• Potencial de Engagement (30%)
- Palabras que indican descubrimientos importantes
- Temas trending en ciencia
- Accesibilidad para audiencia general
- "Factor wow" del contenido

### Interpretando Resultados

```
Score >= 0.8  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  Excelente - Art√≠culo destacado
Score >= 0.6  ‚≠ê‚≠ê‚≠ê‚≠ê    Muy bueno - Alta relevancia
Score >= 0.4  ‚≠ê‚≠ê‚≠ê      Bueno - Relevante
Score >= 0.2  ‚≠ê‚≠ê        Regular - Consideraci√≥n
Score <  0.2  ‚≠ê          Bajo - Probablemente descartado
```

---

## üìÅ Estructura del Proyecto

```
news_collector/
‚îú‚îÄ‚îÄ main.py                 # Orquestador principal
‚îú‚îÄ‚îÄ run_collector.py        # Script de ejecuci√≥n simple
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias Python
‚îú‚îÄ‚îÄ .env.example           # Configuraci√≥n de ejemplo
‚îÇ
‚îú‚îÄ‚îÄ config/                # Configuraci√≥n del sistema
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py        # Configuraci√≥n general
‚îÇ   ‚îî‚îÄ‚îÄ sources.py         # Cat√°logo de fuentes RSS
‚îÇ
‚îú‚îÄ‚îÄ src/                   # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ collectors/        # Sistemas de recolecci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_collector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rss_collector.py
‚îÇ   ‚îú‚îÄ‚îÄ scoring/           # Sistema de scoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basic_scorer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_scorer.py
‚îÇ   ‚îú‚îÄ‚îÄ reranker/          # Capa determin√≠stica de reordenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reranker.py
‚îÇ   ‚îú‚îÄ‚îÄ storage/           # Persistencia de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îî‚îÄ‚îÄ data/                  # Datos del sistema
    ‚îú‚îÄ‚îÄ news.db           # Base de datos SQLite
    ‚îî‚îÄ‚îÄ logs/             # Archivos de log
```

---

## üîç Debugging y Troubleshooting

### Problemas Comunes

#### Error de Dependencias
```bash
# Verificar que todas las dependencias est√©n instaladas
python run_collector.py --check-deps

# Reinstalar dependencias
python -m pip install --require-hashes -r requirements.lock
```

#### Problemas de Red
```bash
# Aumentar timeout en .env
REQUEST_TIMEOUT=60
REQUEST_DELAY=2.0

# Verificar conectividad
ping www.nature.com
```

#### Base de Datos Corrupta
```bash
# Eliminar y recrear base de datos
rm data/news.db
python run_collector.py --dry-run  # Recrear√° la DB
```

### Modo Debug

```bash
# Activar logging detallado
export DEBUG=true
export LOG_LEVEL=DEBUG
python run_collector.py --verbose
```

### Logs √ötiles

```bash
# Ver logs en tiempo real
tail -f data/logs/collector.log

# Buscar errores espec√≠ficos
grep "ERROR" data/logs/collector.log

# Ver estad√≠sticas de fuentes
grep "Art√≠culo guardado" data/logs/collector.log | wc -l
```

---

## üöÄ Optimizaci√≥n y Performance

### Para Vol√∫menes Altos

1. **Usar PostgreSQL**:
```bash
# En .env
DB_TYPE=postgresql
DB_HOST=localhost
DB_NAME=news_collector
DB_USER=collector
DB_PASSWORD=secure_password
```

2. **Ajustar Paralelismo**:
```bash
# Reducir delay entre requests
REQUEST_DELAY=0.5

# Aumentar l√≠mite por fuente
MAX_ARTICLES_PER_SOURCE=100
```

3. **Optimizar Scoring**:
```bash
# Ser m√°s selectivo
MINIMUM_SCORE=0.5
DAILY_TOP_COUNT=15
```

### Monitoreo

```python
# Obtener m√©tricas de performance
stats = system.get_system_statistics()
print(f"Art√≠culos procesados: {stats['daily_statistics']['articles_processed']}")
print(f"Tasa de √©xito: {stats['database_health']['status']}")
```

---

## üîÆ Roadmap Futuro

### Versi√≥n 1.1 - Mejoras de Core
- Procesamiento paralelo de fuentes
- Cache inteligente para evitar re-processing
- API REST para acceso externo
- Dashboard web para monitoreo

### Versi√≥n 1.2 - ML Avanzado
- Modelos de ML para scoring mejorado
- An√°lisis de sentimientos
- Detecci√≥n de temas trending autom√°tica
- Personalizaci√≥n basada en feedback

### Versi√≥n 1.3 - Integraci√≥n
- Webhooks para notificaciones
- Integraci√≥n con redes sociales
- Export a diferentes formatos (JSON, RSS, email)
- Slack/Discord bots

### Versi√≥n 2.0 - Escalabilidad
- Arquitectura distribuida
- Queue systems (Redis/RabbitMQ)
- Multi-idioma support
- Cloud deployment autom√°tico

---

## üõ°Ô∏è Audit & Guardrail

El repositorio incluye un esc√°ner determin√≠stico para encontrar TODOs, placeholders y c√≥digo comentado que haya quedado pendiente.

### Ejecutar el esc√°ner localmente

```bash
make audit-todos
```

Este comando genera los reportes en `reports/placeholders.{csv,json,md}` con el mismo n√∫mero de hallazgos en cada formato.

### Actualizar la l√≠nea base

```bash
make audit-todos-baseline
```

Guarda los resultados actuales en `reports/placeholders.baseline.json`. √ösalo cuando conscientemente cierres o aceptes la deuda t√©cnica existente.

### Verificar regresiones en CI o localmente

```bash
make audit-todos-check
```

Compara el estado actual contra la baseline y falla si aparecen hallazgos nuevos. Puedes permitir cierta tolerancia ajustando la variable `AUDIT_TODOS_MAX_NEW` antes de ejecutar el comando.

En GitHub Actions, el job `audit-todos` ejecuta esta verificaci√≥n en cada push/PR, sube los reportes como artefactos y comenta en el Pull Request cuando aparecen pendientes nuevos.

---

## ü§ù Contribuir

¬°Las contribuciones son bienvenidas! Aqu√≠'s c√≥mo puedes ayudar:

### Reportar Issues
- Usa el template de issue en GitHub
- Incluye logs relevantes
- Describe pasos para reproducir

### Agregar Fuentes
1. Edita `config/sources.py`
2. Agrega tu fuente con metadata completa
3. Testea con `--sources tu_fuente --dry-run`
4. Crea Pull Request

### Mejorar Scoring
1. Modifica `src/scoring/feature_scorer.py` (o `basic_scorer.py` si trabajas en el modo legacy).
2. Ejecuta `python scripts/evaluate_ranking.py` y `python scripts/enrichment_sanity.py`.
3. Agrega/actualiza tests (golden set en `tests/test_enrichment_pipeline.py`).
4. Documenta los cambios en este README y abre un Pull Request.

---

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para detalles.

---

## üôè Agradecimientos

- **Fuentes de Datos**: Gracias a todas las instituciones cient√≠ficas que proporcionan feeds RSS p√∫blicos
- **Bibliotecas Open Source**: feedparser, requests, SQLAlchemy, loguru, y muchas otras
- **Comunidad Cient√≠fica**: Por hacer la informaci√≥n accesible y verificable

---

## üìû Soporte

- **Issues**: [GitHub Issues](https://github.com/noticiencias/noticiencias_news_collector/issues)
- **Discusiones**: [GitHub Discussions](https://github.com/noticiencias/noticiencias_news_collector/discussions)
- **Email**: n/a

---

## üèÜ Stats del Proyecto

Los siguientes indicadores provienen de la √∫ltima ejecuci√≥n verificada de la suite de performance y del replay operacional.

- **‚öôÔ∏è Throughput pipeline (SQLite dev)**: 11.5 art√≠culos/s end-to-end con ingesti√≥n p95 en 128 ms y enriquecimiento p95 en 72 ms.
- **üóÑÔ∏è Throughput pipeline (perfil PostgreSQL simulado)**: 46.6 art√≠culos/s end-to-end con ingesti√≥n p95 en 31.7 ms y pool `QueuePool(12/6)`.
- **üéØ Accuracy del scorer**: error absoluto medio 0.0, 100% de aciertos en `should_include` y ranking id√©ntico al dataset dorado.
- **üì• Escritura PostgreSQL**: 0.024 s de promedio por inserci√≥n (p95 57 ms, m√°x. 97 ms) durante una r√°faga de 60 art√≠culos.
- **üõ°Ô∏è Disponibilidad observada**: 50% de ratio de ingesta normalizado; 2 fuentes auto-suspendidas en el √∫ltimo replay semanal.

### üõ£Ô∏è Roadmap de M√©tricas

- Expandir el monitoreo activo a 15+ fuentes premium con cobertura continua.
- Escalar el throughput sostenido a 50 art√≠culos/segundo en producci√≥n.
- Mantener disponibilidad ‚â•99.9% en ventanas mensuales.
- Automatizar el procesamiento de 1 000+ art√≠culos/d√≠a.

---

*Construido con ‚ù§Ô∏è para la comunidad cient√≠fica hispanohablante*
