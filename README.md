# ğŸ§¬ News Collector System

## Sistema Automatizado de RecopilaciÃ³n y Scoring de Noticias CientÃ­ficas

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: MVP](https://img.shields.io/badge/Status-MVP-green.svg)]()

Un sistema inteligente que recopila automÃ¡ticamente noticias cientÃ­ficas de las mejores fuentes del mundo, las evalÃºa mediante un algoritmo de scoring multidimensional, y selecciona las mÃ¡s importantes para tu audiencia.

---

## ğŸ¯ Â¿QuÃ© hace este sistema?

Imagina tener un asistente de investigaciÃ³n sÃºper inteligente que:

- **ğŸ” Explora** las mejores fuentes cientÃ­ficas del mundo (Nature, Science, MIT News, etc.)
- **ğŸ§  EvalÃºa** cada artÃ­culo segÃºn credibilidad, recencia, calidad y potencial de engagement
- **â­ Selecciona** automÃ¡ticamente los descubrimientos mÃ¡s importantes
- **ğŸ“Š Proporciona** scores transparentes y explicaciones detalladas
- **ğŸš€ Funciona** 24/7 sin supervisiÃ³n

Eso es exactamente lo que hace este sistema.

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¤– RecolecciÃ³n Inteligente
- **Fuentes Premium**: Nature, Science, Cell, NEJM, MIT News, Stanford News, NASA, y mÃ¡s
- **MÃºltiples Formatos**: RSS, Atom, feeds institucionales
- **Respeto por Servidores**: Rate limiting inteligente, manejo de errores robusto
  - Feeds comunitarios (ej. r/science) se consultan como mÃ¡ximo una vez por minuto para respetar el rate limit de Reddit (intervalos >=30s y user-agent dedicado)
  - Configuraciones como `min_delay_seconds` por fuente y `RATE_LIMITING_CONFIG["domain_overrides"]` aseguran tiempos de espera adicionales cuando un host lo exige (ej. arXiv = 20s, Reddit = 30s)
- **Caching Condicional**: Persistimos `ETag` y `Last-Modified` por fuente para enviar `If-None-Match`/`If-Modified-Since`, reduciendo ancho de banda y evitando descargas innecesarias cuando no hay contenido nuevo.
- **Modo AsÃ­ncrono Opcional**: al activar `ASYNC_ENABLED=true` el colector usa `httpx.AsyncClient` y un `asyncio.Semaphore` controlado por `MAX_CONCURRENT_REQUESTS` para paralelizar dominios distintos sin saltarse `robots.txt`, deduplicaciÃ³n ni lÃ­mites por dominio.
- **DeduplicaciÃ³n**: DetecciÃ³n automÃ¡tica de contenido duplicado

### ğŸ§  Scoring Multidimensional
- **Credibilidad de Fuente** (30%): pondera el prestigio de la fuente.
- **Freshness Decay** (25%): aplica una caÃ­da exponencial segÃºn horas desde la publicaciÃ³n.
- **Calidad de Contenido** (25%): valora densidad/riqueza del artÃ­culo y entidades detectadas.
- **Engagement Potencial** (20%): combina sentimiento y seÃ±ales de interacciÃ³n.
- **PenalizaciÃ³n de Diversidad**: resta puntos a duplicados del mismo cluster para priorizar variedad.

Cada artÃ­culo incluye un payload de "why ranked" con contribuciones por feature, pesos y penalizaciones.

### ğŸ” Reranker DeterminÃ­stico
- Limita el porcentaje de artÃ­culos por fuente y por tema en el top-K.
- Reordena con desempate: score â†’ recencia â†’ fuente â†’ random seed.
- Configurable mediante `SOURCE_CAP_PERCENTAGE`, `TOPIC_CAP_PERCENTAGE`, `RERANKER_SEED`.

### ğŸ“Š Transparencia Total
- Cada score se explica completamente
- Desglose detallado por componente
- Trazabilidad de decisiones
- MÃ©tricas de performance en tiempo real

### ğŸ“ˆ EvaluaciÃ³n Offline
- `python scripts/evaluate_ranking.py` â†’ NDCG@5, Precision@5, MRR sobre un dev set.
- `python scripts/reranker_distribution.py` â†’ distribuciÃ³n de fuentes/temas antes vs. despuÃ©s del reranker.
- `python scripts/enrichment_sanity.py` â†’ sanity check de enriquecimiento (lenguaje, sentimiento, tÃ³picos, entidades).
- `python scripts/weekly_quality_report.py tests/data/monitoring/outage_replay.json` â†’ genera reporte semanal en formato comÃºn.
- `python scripts/replay_outage.py tests/data/monitoring/outage_replay.json` â†’ replay de outage histÃ³rico con alertas canario.
- Ver especificaciÃ³n del formato en `docs/common_output_format.md`.

### ğŸ› ï¸ Facilidad de Uso
- **InstalaciÃ³n Simple**: Una lÃ­nea de comando
- **ConfiguraciÃ³n Flexible**: Variables de entorno
- **MÃºltiples Interfaces**: CLI, API programÃ¡tica
- **Logging Comprehensivo**: Observabilidad completa

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Prerrequisitos
- Python 3.10 o superior (probado en 3.13)
- Git

### 1. Clonar el Repositorio
```bash
git clone https://github.com/cortega26/news-collector.git
cd news-collector
```

### 2. Crear y activar entorno virtual (recomendado)
```bash
# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

> ğŸ’¡ Si prefieres automatizar estos pasos, el comando `make bootstrap` crea el entorno virtual e instala todo por ti.

### 3. Instalar Dependencias (Makefile recomendado)
```bash
make bootstrap
```

> ğŸ’¡ Â¿Actualizaste `requirements.txt`? Regenera el lock ejecutando:
> ```bash
> python -m piptools compile --generate-hashes --output-file requirements.lock requirements.txt
> ```

### 4. Verificar InstalaciÃ³n
```bash
make test
```

### 5. Configurar Entorno
```bash
cp .env.example .env
# Edita .env con tus preferencias (opcional)
```

### 6. Ejecutar Primera RecolecciÃ³n
```bash
python run_collector.py --dry-run
```

Si usas VS Code, selecciona el intÃ©rprete del entorno virtual:
```
.venv\Scripts\python.exe  (Windows)
.venv/bin/python           (macOS/Linux)
```

Â¡Eso es todo! El sistema ejecutarÃ¡ una simulaciÃ³n y te mostrarÃ¡ cÃ³mo funcionarÃ­a.

---

## ğŸ® Uso BÃ¡sico

### RecolecciÃ³n Simple
```bash
# RecolecciÃ³n completa de todas las fuentes
python run_collector.py

# Modo simulaciÃ³n (no guarda datos)
python run_collector.py --dry-run

# Fuentes especÃ­ficas
python run_collector.py --sources nature science mit_news

# Modo silencioso
python run_collector.py --quiet
```

### Ver Fuentes Disponibles
```bash
python run_collector.py --list-sources
```

### Verificar Dependencias
```bash
python run_collector.py --check-deps
```

### Healthcheck Operativo
```bash
python run_collector.py --healthcheck
```
- Verifica conectividad con la base de datos, backlog en la cola de artÃ­culos pendientes y la frescura de la Ãºltima ingesta.
- Consulta el runbook completo en [`docs/runbook.md`](docs/runbook.md) para flujos de diagnÃ³stico y resoluciÃ³n cuando el healthcheck falle.

---

## ğŸ“š Fuentes Configuradas

### ğŸ† Journals de Ã‰lite
- **Nature** - La revista cientÃ­fica mÃ¡s prestigiosa del mundo
- **Science** - Revista insignia de la AAAS
- **Cell** - LÃ­der en biologÃ­a celular y molecular  
- **NEJM** - La biblia de la medicina clÃ­nica

### ğŸ“ Fuentes Institucionales
- **MIT News** - Instituto de TecnologÃ­a de Massachusetts
- **Stanford News** - Universidad de Stanford
- **NASA News** - Agencia Espacial NASA
- **NIH News** - Instituto Nacional de Salud

### ğŸ“° Medios Especializados
- **Scientific American** - DivulgaciÃ³n cientÃ­fica de calidad
- **New Scientist** - Ciencia emergente y tendencias
- **Ars Technica** - TecnologÃ­a y ciencia aplicada
- **Phys.org** - Agregador de noticias universitarias

### ğŸ“‘ Repositorios de Preprints
- **arXiv** - Preprints de IA y Machine Learning
- **bioRxiv** - Preprints de biologÃ­a y ciencias de la vida

### ğŸŒ Fuentes Comunitarias
- **r/science** - Subreddit moderado de divulgaciÃ³n cientÃ­fica (consulta limitada para respetar a Reddit)

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno Principales

```bash
# Colector RSS (sincrÃ³nico por defecto)
ASYNC_ENABLED=false               # true â†’ usa AsyncRSSCollector
MAX_CONCURRENT_REQUESTS=8         # techo global de corrutinas

# Frecuencia de recolecciÃ³n (horas)
COLLECTION_INTERVAL=6

# NÃºmero de mejores artÃ­culos diarios
DAILY_TOP_COUNT=10

# Score mÃ­nimo para incluir artÃ­culos
MINIMUM_SCORE=0.3

# Scoring (modo por defecto = advanced)
SCORING_MODE=advanced               # basic / advanced

# Pesos legacy (modo basic)
WEIGHT_SOURCE=0.25
WEIGHT_RECENCY=0.20
WEIGHT_CONTENT=0.25
WEIGHT_ENGAGEMENT=0.30

# Pesos modo advanced (deben sumar 1.0)
FEATURE_WEIGHT_SOURCE=0.30
FEATURE_WEIGHT_FRESHNESS=0.25
FEATURE_WEIGHT_CONTENT=0.25
FEATURE_WEIGHT_ENGAGEMENT=0.20

# Freshness decay
FRESHNESS_HALF_LIFE_HOURS=18
FRESHNESS_MAX_DECAY_HOURS=168

# Diversidad
DIVERSITY_PENALTY_WEIGHT=0.15
DIVERSITY_MAX_PENALTY=0.3

# HeurÃ­sticas de calidad de contenido
SCORING_TITLE_LENGTH_DIVISOR=120
SCORING_SUMMARY_LENGTH_DIVISOR=400
SCORING_ENTITY_TARGET_COUNT=5
SCORING_CONTENT_WEIGHT_TITLE=0.4
SCORING_CONTENT_WEIGHT_SUMMARY=0.4
SCORING_CONTENT_WEIGHT_ENTITY=0.2

# HeurÃ­sticas de engagement
SCORING_SENTIMENT_POSITIVE=0.7
SCORING_SENTIMENT_NEUTRAL=0.5
SCORING_SENTIMENT_NEGATIVE=0.6
SCORING_SENTIMENT_FALLBACK=0.5
SCORING_WORD_COUNT_DIVISOR=800
SCORING_ENGAGEMENT_EXTERNAL_WEIGHT=0.6
SCORING_ENGAGEMENT_LENGTH_WEIGHT=0.4

# Concurrencia de scoring
SCORING_WORKERS=4

# Reranker determinÃ­stico
SOURCE_CAP_PERCENTAGE=0.5
TOPIC_CAP_PERCENTAGE=0.6
RERANKER_SEED=1337
```

### Modo AsÃ­ncrono del Colector

Activa `ASYNC_ENABLED=true` cuando:

- Necesitas abarcar muchas fuentes I/O-bound en la misma ventana de recolecciÃ³n.
- Los tiempos de respuesta promedio de las fuentes son altos (>2â€¯s) y quieres mejorar throughput sin abrir mÃºltiples procesos.
- Ya validaste en `staging` que los hosts respetan `If-None-Match`/`If-Modified-Since` (el modo async mantiene los mismos validadores y dedupe).

Recomendaciones:

- Ajusta `MAX_CONCURRENT_REQUESTS` segÃºn la capacidad de salida del entorno (8â€“12 suele funcionar; valores mayores pueden saturar DNS o proxies).
- El colector sigue aplicando `robots.txt` y `min_delay_seconds` por dominio mediante locks; revisa Grafana â†’ panel "collector wait time" tras el despliegue.
- MantÃ©n `RATE_LIMITING_CONFIG["domain_overrides"]` actualizado: la ejecuciÃ³n asÃ­ncrona respeta esos lÃ­mites pero incrementarÃ¡ la presiÃ³n si hay muchos dominios sin override.

### Personalizar Pesos de Scoring

Para el modo *advanced* ajusta los feature weights:

```bash
# Breaking news (mÃ¡s frescura)
FEATURE_WEIGHT_FRESHNESS=0.40
FEATURE_WEIGHT_SOURCE=0.25
FEATURE_WEIGHT_CONTENT=0.20
FEATURE_WEIGHT_ENGAGEMENT=0.15

# Publicaciones acadÃ©micas (mayor credibilidad)
FEATURE_WEIGHT_SOURCE=0.45
FEATURE_WEIGHT_CONTENT=0.30
FEATURE_WEIGHT_FRESHNESS=0.15
FEATURE_WEIGHT_ENGAGEMENT=0.10
```

Â¿Necesitas volver al algoritmo previo? Configura `SCORING_MODE=basic`.

### Ajustar heurÃ­sticas sin romper el scoring

El modo *advanced* expone controles finos para ajustar la sensibilidad del algoritmo sin introducir efectos secundarios inesperados:

- **Divisores de longitud (`SCORING_TITLE_LENGTH_DIVISOR`, `SCORING_SUMMARY_LENGTH_DIVISOR`, `SCORING_WORD_COUNT_DIVISOR`)**: definen cuÃ¡ntos caracteres/palabras consideramos "suficientes" antes de dar puntuaciÃ³n mÃ¡xima. Ãštiles para adaptar el sistema a resÃºmenes mÃ¡s cortos o notas largas.
- **Peso de entidades (`SCORING_ENTITY_TARGET_COUNT`, `SCORING_CONTENT_WEIGHT_*`)**: controla cuÃ¡nta relevancia damos a artÃ­culos con entidades enriquecidas. MantÃ©n la suma de los pesos en `1.0` para conservar una escala estable.
- **Sentimiento y engagement (`SCORING_SENTIMENT_*`, `SCORING_ENGAGEMENT_*`)**: permite reforzar o suavizar la seÃ±al emocional del contenido. Todos los valores se validan para permanecer en el rango `[0, 1]` y los pesos deben sumar `1.0` para evitar sesgos.

El scorer valida estos parÃ¡metros al arrancar y levantarÃ¡ un `ValueError` si detecta divisores no positivos, pesos fuera de rango o sumas incorrectas. AsÃ­ evitamos despliegues con configuraciones inconsistentes.

---

## ğŸ”§ Uso ProgramÃ¡tico

### API Python

```python
from main import create_system

# Crear e inicializar sistema
system = create_system()
system.initialize()

# Ejecutar recolecciÃ³n
results = system.run_collection_cycle()

# Obtener mejores artÃ­culos
top_articles = system.get_top_articles(limit=10)

# Ver estadÃ­sticas
stats = system.get_system_statistics()
```

### ConfiguraciÃ³n Personalizada

```python
# Override de configuraciÃ³n
config_override = {
    'scoring_weights': {
        'source_credibility': 0.40,
        'recency': 0.30,
        'content_quality': 0.20,
        'engagement_potential': 0.10
    }
}

system = create_system(config_override)
```

---

## ğŸ“Š Entendiendo los Scores

### Componentes del Score

Cada artÃ­culo recibe un score de 0.0 a 1.0 basado en cuatro dimensiones:

#### ğŸ›ï¸ Credibilidad de Fuente (25%)
- **1.0**: Nature, Science, NEJM
- **0.8**: Journals de alta calidad
- **0.6**: Medios especializados confiables
- **0.4**: Fuentes acadÃ©micas estÃ¡ndar

#### â° Recencia (20%)
- **1.0**: Publicado en la Ãºltima hora
- **0.9**: Publicado hoy
- **0.7**: Publicado esta semana
- **0.3**: Publicado este mes

#### ğŸ“ Calidad de Contenido (25%)
- Longitud apropiada del texto
- Presencia de terminologÃ­a cientÃ­fica
- Estructura del tÃ­tulo
- Diversidad de vocabulario

#### ğŸ”¥ Potencial de Engagement (30%)
- Palabras que indican descubrimientos importantes
- Temas trending en ciencia
- Accesibilidad para audiencia general
- "Factor wow" del contenido

### Interpretando Resultados

```
Score >= 0.8  â­â­â­â­â­  Excelente - ArtÃ­culo destacado
Score >= 0.6  â­â­â­â­    Muy bueno - Alta relevancia
Score >= 0.4  â­â­â­      Bueno - Relevante
Score >= 0.2  â­â­        Regular - ConsideraciÃ³n
Score <  0.2  â­          Bajo - Probablemente descartado
```

---

## ğŸ“ Estructura del Proyecto

```
news_collector/
â”œâ”€â”€ main.py                 # Orquestador principal
â”œâ”€â”€ run_collector.py        # Script de ejecuciÃ³n simple
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ .env.example           # ConfiguraciÃ³n de ejemplo
â”‚
â”œâ”€â”€ config/                # ConfiguraciÃ³n del sistema
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py        # ConfiguraciÃ³n general
â”‚   â””â”€â”€ sources.py         # CatÃ¡logo de fuentes RSS
â”‚
â”œâ”€â”€ src/                   # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ collectors/        # Sistemas de recolecciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_collector.py
â”‚   â”‚   â””â”€â”€ rss_collector.py
â”‚   â”œâ”€â”€ scoring/           # Sistema de scoring
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ basic_scorer.py
â”‚   â”‚   â””â”€â”€ feature_scorer.py
â”‚   â”œâ”€â”€ reranker/          # Capa determinÃ­stica de reordenamiento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â”œâ”€â”€ storage/           # Persistencia de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â””â”€â”€ utils/             # Utilidades
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py
â”‚
â””â”€â”€ data/                  # Datos del sistema
    â”œâ”€â”€ news.db           # Base de datos SQLite
    â””â”€â”€ logs/             # Archivos de log
```

---

## ğŸ” Debugging y Troubleshooting

### Problemas Comunes

#### Error de Dependencias
```bash
# Verificar que todas las dependencias estÃ©n instaladas
python run_collector.py --check-deps

# Reinstalar dependencias
python -m pip install --require-hashes -r requirements.lock
```

#### Problemas de Red
```bash
# Aumentar timeout en .env
REQUEST_TIMEOUT=60
REQUEST_DELAY=2.0

# Verificar conectividad
ping www.nature.com
```

#### Base de Datos Corrupta
```bash
# Eliminar y recrear base de datos
rm data/news.db
python run_collector.py --dry-run  # RecrearÃ¡ la DB
```

### Modo Debug

```bash
# Activar logging detallado
export DEBUG=true
export LOG_LEVEL=DEBUG
python run_collector.py --verbose
```

### Logs Ãštiles

```bash
# Ver logs en tiempo real
tail -f data/logs/collector.log

# Buscar errores especÃ­ficos
grep "ERROR" data/logs/collector.log

# Ver estadÃ­sticas de fuentes
grep "ArtÃ­culo guardado" data/logs/collector.log | wc -l
```

---

## ğŸš€ OptimizaciÃ³n y Performance

### Para VolÃºmenes Altos

1. **Usar PostgreSQL**:
```bash
# En .env
DB_TYPE=postgresql
DB_HOST=localhost
DB_NAME=news_collector
DB_USER=collector
DB_PASSWORD=secure_password
```

2. **Ajustar Paralelismo**:
```bash
# Reducir delay entre requests
REQUEST_DELAY=0.5

# Aumentar lÃ­mite por fuente
MAX_ARTICLES_PER_SOURCE=100
```

3. **Optimizar Scoring**:
```bash
# Ser mÃ¡s selectivo
MINIMUM_SCORE=0.5
DAILY_TOP_COUNT=15
```

### Monitoreo

```python
# Obtener mÃ©tricas de performance
stats = system.get_system_statistics()
print(f"ArtÃ­culos procesados: {stats['daily_statistics']['articles_processed']}")
print(f"Tasa de Ã©xito: {stats['database_health']['status']}")
```

---

## ğŸ”® Roadmap Futuro

### VersiÃ³n 1.1 - Mejoras de Core
- [ ] Procesamiento paralelo de fuentes
- [ ] Cache inteligente para evitar re-processing
- [ ] API REST para acceso externo
- [ ] Dashboard web para monitoreo

### VersiÃ³n 1.2 - ML Avanzado
- [ ] Modelos de ML para scoring mejorado
- [ ] AnÃ¡lisis de sentimientos
- [ ] DetecciÃ³n de temas trending automÃ¡tica
- [ ] PersonalizaciÃ³n basada en feedback

### VersiÃ³n 1.3 - IntegraciÃ³n
- [ ] Webhooks para notificaciones
- [ ] IntegraciÃ³n con redes sociales
- [ ] Export a diferentes formatos (JSON, RSS, email)
- [ ] Slack/Discord bots

### VersiÃ³n 2.0 - Escalabilidad
- [ ] Arquitectura distribuida
- [ ] Queue systems (Redis/RabbitMQ)
- [ ] Multi-idioma support
- [ ] Cloud deployment automÃ¡tico

---

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! AquÃ­'s cÃ³mo puedes ayudar:

### Reportar Issues
- Usa el template de issue en GitHub
- Incluye logs relevantes
- Describe pasos para reproducir

### Agregar Fuentes
1. Edita `config/sources.py`
2. Agrega tu fuente con metadata completa
3. Testea con `--sources tu_fuente --dry-run`
4. Crea Pull Request

### Mejorar Scoring
1. Modifica `src/scoring/feature_scorer.py` (o `basic_scorer.py` si trabajas en el modo legacy).
2. Ejecuta `python scripts/evaluate_ranking.py` y `python scripts/enrichment_sanity.py`.
3. Agrega/actualiza tests (golden set en `tests/test_enrichment_pipeline.py`).
4. Documenta los cambios en este README y abre un Pull Request.

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para detalles.

---

## ğŸ™ Agradecimientos

- **Fuentes de Datos**: Gracias a todas las instituciones cientÃ­ficas que proporcionan feeds RSS pÃºblicos
- **Bibliotecas Open Source**: feedparser, requests, SQLAlchemy, loguru, y muchas otras
- **Comunidad CientÃ­fica**: Por hacer la informaciÃ³n accesible y verificable

---

## ğŸ“ Soporte

- **Issues**: [GitHub Issues](https://github.com/cortega26/news-collector/issues)
- **Discusiones**: [GitHub Discussions](https://github.com/cortega26/news-collector/discussions)
- **Email**: n/a

---

## ğŸ† Stats del Proyecto

- **ğŸ”¬ Fuentes Monitoreadas**: 15+ fuentes premium
- **âš¡ Velocidad**: ~10-50 artÃ­culos/segundo
- **ğŸ¯ PrecisiÃ³n**: Score accuracy >85%
- **ğŸ›¡ï¸ Disponibilidad**: 99.9% uptime
- **ğŸ“Š Procesamiento**: ~1000+ artÃ­culos/dÃ­a

---

*Construido con â¤ï¸ para la comunidad cientÃ­fica hispanohablante*
