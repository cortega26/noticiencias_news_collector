# üß¨ News Collector System

## Sistema Automatizado de Recopilaci√≥n y Scoring de Noticias Cient√≠ficas

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: MVP](https://img.shields.io/badge/Status-MVP-green.svg)]()

Un sistema inteligente que recopila autom√°ticamente noticias cient√≠ficas de las mejores fuentes del mundo, las eval√∫a mediante un algoritmo de scoring multidimensional, y selecciona las m√°s importantes para tu audiencia.

---

## üéØ ¬øQu√© hace este sistema?

Imagina tener un asistente de investigaci√≥n s√∫per inteligente que:

- **üîç Explora** las mejores fuentes cient√≠ficas del mundo (Nature, Science, MIT News, etc.)
- **üß† Eval√∫a** cada art√≠culo seg√∫n credibilidad, recencia, calidad y potencial de engagement
- **‚≠ê Selecciona** autom√°ticamente los descubrimientos m√°s importantes
- **üìä Proporciona** scores transparentes y explicaciones detalladas
- **üöÄ Funciona** 24/7 sin supervisi√≥n

Eso es exactamente lo que hace este sistema.

---

## ‚ú® Caracter√≠sticas Principales

### ü§ñ Recolecci√≥n Inteligente
- **Fuentes Premium**: Nature, Science, Cell, NEJM, MIT News, Stanford News, NASA, y m√°s
- **M√∫ltiples Formatos**: RSS, Atom, feeds institucionales
- **Respeto por Servidores**: Rate limiting inteligente, manejo de errores robusto
  - Feeds comunitarios (ej. r/science) se consultan como m√°ximo una vez por minuto para respetar el rate limit de Reddit (intervalos >=30s y user-agent dedicado)
  - Configuraciones como `min_delay_seconds` por fuente y `RATE_LIMITING_CONFIG["domain_overrides"]` aseguran tiempos de espera adicionales cuando un host lo exige (ej. arXiv = 20s, Reddit = 30s)
- **Caching Condicional**: Persistimos `ETag` y `Last-Modified` por fuente para enviar `If-None-Match`/`If-Modified-Since`, reduciendo ancho de banda y evitando descargas innecesarias cuando no hay contenido nuevo.
- **Modo As√≠ncrono Opcional**: al activar `ASYNC_ENABLED=true` el colector usa `httpx.AsyncClient` y un `asyncio.Semaphore` controlado por `MAX_CONCURRENT_REQUESTS` para paralelizar dominios distintos sin saltarse `robots.txt`, deduplicaci√≥n ni l√≠mites por dominio.
- **Deduplicaci√≥n**: Detecci√≥n autom√°tica de contenido duplicado

### üß† Scoring Multidimensional
- **Credibilidad de Fuente** (30%): pondera el prestigio de la fuente.
- **Freshness Decay** (25%): aplica una ca√≠da exponencial seg√∫n horas desde la publicaci√≥n.
- **Calidad de Contenido** (25%): valora densidad/riqueza del art√≠culo y entidades detectadas.
- **Engagement Potencial** (20%): combina sentimiento y se√±ales de interacci√≥n.
- **Penalizaci√≥n de Diversidad**: resta puntos a duplicados del mismo cluster para priorizar variedad.

Cada art√≠culo incluye un payload de "why ranked" con contribuciones por feature, pesos y penalizaciones.

### üîÅ Reranker Determin√≠stico
- Limita el porcentaje de art√≠culos por fuente y por tema en el top-K.
- Reordena con desempate: score ‚Üí recencia ‚Üí fuente ‚Üí random seed.
- Configurable mediante `SOURCE_CAP_PERCENTAGE`, `TOPIC_CAP_PERCENTAGE`, `RERANKER_SEED`.

### üìä Transparencia Total
- Cada score se explica completamente
- Desglose detallado por componente
- Trazabilidad de decisiones
- M√©tricas de performance en tiempo real

### üìà Evaluaci√≥n Offline
- `python scripts/evaluate_ranking.py` ‚Üí NDCG@5, Precision@5, MRR sobre un dev set.
- `python scripts/reranker_distribution.py` ‚Üí distribuci√≥n de fuentes/temas antes vs. despu√©s del reranker.
- `python scripts/enrichment_sanity.py` ‚Üí sanity check de enriquecimiento (lenguaje, sentimiento, t√≥picos, entidades).
- `python scripts/weekly_quality_report.py tests/data/monitoring/outage_replay.json` ‚Üí genera reporte semanal en formato com√∫n.
- `python scripts/replay_outage.py tests/data/monitoring/outage_replay.json` ‚Üí replay de outage hist√≥rico con alertas canario.
- Ver especificaci√≥n del formato en `docs/common_output_format.md`.

### üõ†Ô∏è Facilidad de Uso
- **Instalaci√≥n Simple**: Una l√≠nea de comando
- **Configuraci√≥n Flexible**: Variables de entorno
- **M√∫ltiples Interfaces**: CLI, API program√°tica
- **Logging Comprehensivo**: Observabilidad completa

---

## üöÄ Instalaci√≥n R√°pida

### Prerrequisitos
- Python 3.10 o superior (probado en 3.13)
- Git

### 1. Clonar el Repositorio
```bash
git clone https://github.com/cortega26/news-collector.git
cd news-collector
```

### 2. Crear y activar entorno virtual (recomendado)
```bash
# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

> üí° Si prefieres automatizar estos pasos, el comando `make bootstrap` crea el entorno virtual e instala todo por ti.

### 3. Instalar Dependencias (Makefile recomendado)
```bash
make bootstrap
```

> üí° ¬øActualizaste `requirements.txt`? Regenera el lock ejecutando:
> ```bash
> python -m piptools compile --generate-hashes --output-file requirements.lock requirements.txt
> ```

### 4. Verificar Instalaci√≥n
```bash
make test
```

### 5. Configurar Entorno
```bash
cp .env.example .env
# Edita .env con tus preferencias (opcional)
```

### 6. Ejecutar Primera Recolecci√≥n
```bash
python run_collector.py --dry-run
```

Si usas VS Code, selecciona el int√©rprete del entorno virtual:
```
.venv\Scripts\python.exe  (Windows)
.venv/bin/python           (macOS/Linux)
```

¬°Eso es todo! El sistema ejecutar√° una simulaci√≥n y te mostrar√° c√≥mo funcionar√≠a.

---

## üéÆ Uso B√°sico

### Recolecci√≥n Simple
```bash
# Recolecci√≥n completa de todas las fuentes
python run_collector.py

# Modo simulaci√≥n (no guarda datos)
python run_collector.py --dry-run

# Fuentes espec√≠ficas
python run_collector.py --sources nature science mit_news

# Modo silencioso
python run_collector.py --quiet
```

### Ver Fuentes Disponibles
```bash
python run_collector.py --list-sources
```

### Verificar Dependencias
```bash
python run_collector.py --check-deps
```

### Healthcheck Operativo
```bash
python run_collector.py --healthcheck
```
- Verifica conectividad con la base de datos, backlog en la cola de art√≠culos pendientes y la frescura de la √∫ltima ingesta.
- Consulta el runbook completo en [`docs/runbook.md`](docs/runbook.md) para flujos de diagn√≥stico y resoluci√≥n cuando el healthcheck falle.

---

## üìö Fuentes Configuradas

### üèÜ Journals de √âlite
- **Nature** - La revista cient√≠fica m√°s prestigiosa del mundo
- **Science** - Revista insignia de la AAAS
- **Cell** - L√≠der en biolog√≠a celular y molecular  
- **NEJM** - La biblia de la medicina cl√≠nica

### üéì Fuentes Institucionales
- **MIT News** - Instituto de Tecnolog√≠a de Massachusetts
- **Stanford News** - Universidad de Stanford
- **NASA News** - Agencia Espacial NASA
- **NIH News** - Instituto Nacional de Salud

### üì∞ Medios Especializados
- **Scientific American** - Divulgaci√≥n cient√≠fica de calidad
- **New Scientist** - Ciencia emergente y tendencias
- **Ars Technica** - Tecnolog√≠a y ciencia aplicada
- **Phys.org** - Agregador de noticias universitarias

### üìë Repositorios de Preprints
- **arXiv** - Preprints de IA y Machine Learning
- **bioRxiv** - Preprints de biolog√≠a y ciencias de la vida

### üåê Fuentes Comunitarias
- **r/science** - Subreddit moderado de divulgaci√≥n cient√≠fica (consulta limitada para respetar a Reddit)

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno Principales

```bash
# Colector RSS (sincr√≥nico por defecto)
ASYNC_ENABLED=false               # true ‚Üí usa AsyncRSSCollector
MAX_CONCURRENT_REQUESTS=8         # techo global de corrutinas

# Frecuencia de recolecci√≥n (horas)
COLLECTION_INTERVAL=6

# N√∫mero de mejores art√≠culos diarios
DAILY_TOP_COUNT=10

# Score m√≠nimo para incluir art√≠culos
MINIMUM_SCORE=0.3

# Scoring (modo por defecto = advanced)
SCORING_MODE=advanced               # basic / advanced

# Pesos legacy (modo basic)
WEIGHT_SOURCE=0.25
WEIGHT_RECENCY=0.20
WEIGHT_CONTENT=0.25
WEIGHT_ENGAGEMENT=0.30

# Pesos modo advanced (deben sumar 1.0)
FEATURE_WEIGHT_SOURCE=0.30
FEATURE_WEIGHT_FRESHNESS=0.25
FEATURE_WEIGHT_CONTENT=0.25
FEATURE_WEIGHT_ENGAGEMENT=0.20

# Freshness decay
FRESHNESS_HALF_LIFE_HOURS=18
FRESHNESS_MAX_DECAY_HOURS=168

# Diversidad
DIVERSITY_PENALTY_WEIGHT=0.15
DIVERSITY_MAX_PENALTY=0.3

# Heur√≠sticas de calidad de contenido
SCORING_TITLE_LENGTH_DIVISOR=120
SCORING_SUMMARY_LENGTH_DIVISOR=400
SCORING_ENTITY_TARGET_COUNT=5
SCORING_CONTENT_WEIGHT_TITLE=0.4
SCORING_CONTENT_WEIGHT_SUMMARY=0.4
SCORING_CONTENT_WEIGHT_ENTITY=0.2

# Heur√≠sticas de engagement
SCORING_SENTIMENT_POSITIVE=0.7
SCORING_SENTIMENT_NEUTRAL=0.5
SCORING_SENTIMENT_NEGATIVE=0.6
SCORING_SENTIMENT_FALLBACK=0.5
SCORING_WORD_COUNT_DIVISOR=800
SCORING_ENGAGEMENT_EXTERNAL_WEIGHT=0.6
SCORING_ENGAGEMENT_LENGTH_WEIGHT=0.4

# Concurrencia de scoring
SCORING_WORKERS=4

# Reranker determin√≠stico
SOURCE_CAP_PERCENTAGE=0.5
TOPIC_CAP_PERCENTAGE=0.6
RERANKER_SEED=1337
```

### Modo As√≠ncrono del Colector

Activa `ASYNC_ENABLED=true` cuando:

- Necesitas abarcar muchas fuentes I/O-bound en la misma ventana de recolecci√≥n.
- Los tiempos de respuesta promedio de las fuentes son altos (>2‚ÄØs) y quieres mejorar throughput sin abrir m√∫ltiples procesos.
- Ya validaste en `staging` que los hosts respetan `If-None-Match`/`If-Modified-Since` (el modo async mantiene los mismos validadores y dedupe).

Recomendaciones:

- Ajusta `MAX_CONCURRENT_REQUESTS` seg√∫n la capacidad de salida del entorno (8‚Äì12 suele funcionar; valores mayores pueden saturar DNS o proxies).
- El colector sigue aplicando `robots.txt` y `min_delay_seconds` por dominio mediante locks; revisa Grafana ‚Üí panel "collector wait time" tras el despliegue.
- Mant√©n `RATE_LIMITING_CONFIG["domain_overrides"]` actualizado: la ejecuci√≥n as√≠ncrona respeta esos l√≠mites pero incrementar√° la presi√≥n si hay muchos dominios sin override.

### Personalizar Pesos de Scoring

Para el modo *advanced* ajusta los feature weights:

```bash
# Breaking news (m√°s frescura)
FEATURE_WEIGHT_FRESHNESS=0.40
FEATURE_WEIGHT_SOURCE=0.25
FEATURE_WEIGHT_CONTENT=0.20
FEATURE_WEIGHT_ENGAGEMENT=0.15

# Publicaciones acad√©micas (mayor credibilidad)
FEATURE_WEIGHT_SOURCE=0.45
FEATURE_WEIGHT_CONTENT=0.30
FEATURE_WEIGHT_FRESHNESS=0.15
FEATURE_WEIGHT_ENGAGEMENT=0.10
```

¬øNecesitas volver al algoritmo previo? Configura `SCORING_MODE=basic`.

### Ajustar heur√≠sticas sin romper el scoring

El modo *advanced* expone controles finos para ajustar la sensibilidad del algoritmo sin introducir efectos secundarios inesperados:

- **Divisores de longitud (`SCORING_TITLE_LENGTH_DIVISOR`, `SCORING_SUMMARY_LENGTH_DIVISOR`, `SCORING_WORD_COUNT_DIVISOR`)**: definen cu√°ntos caracteres/palabras consideramos "suficientes" antes de dar puntuaci√≥n m√°xima. √ötiles para adaptar el sistema a res√∫menes m√°s cortos o notas largas.
- **Peso de entidades (`SCORING_ENTITY_TARGET_COUNT`, `SCORING_CONTENT_WEIGHT_*`)**: controla cu√°nta relevancia damos a art√≠culos con entidades enriquecidas. Mant√©n la suma de los pesos en `1.0` para conservar una escala estable.
- **Sentimiento y engagement (`SCORING_SENTIMENT_*`, `SCORING_ENGAGEMENT_*`)**: permite reforzar o suavizar la se√±al emocional del contenido. Todos los valores se validan para permanecer en el rango `[0, 1]` y los pesos deben sumar `1.0` para evitar sesgos.

El scorer valida estos par√°metros al arrancar y levantar√° un `ValueError` si detecta divisores no positivos, pesos fuera de rango o sumas incorrectas. As√≠ evitamos despliegues con configuraciones inconsistentes.

---

## üîß Uso Program√°tico

### API Python

```python
from main import create_system

# Crear e inicializar sistema
system = create_system()
system.initialize()

# Ejecutar recolecci√≥n
results = system.run_collection_cycle()

# Obtener mejores art√≠culos
top_articles = system.get_top_articles(limit=10)

# Ver estad√≠sticas
stats = system.get_system_statistics()
```

### Configuraci√≥n Personalizada

```python
# Override de configuraci√≥n
config_override = {
    'scoring_weights': {
        'source_credibility': 0.40,
        'recency': 0.30,
        'content_quality': 0.20,
        'engagement_potential': 0.10
    }
}

system = create_system(config_override)
```

---

## üìä Entendiendo los Scores

### Componentes del Score

Cada art√≠culo recibe un score de 0.0 a 1.0 basado en cuatro dimensiones:

#### üèõÔ∏è Credibilidad de Fuente (25%)
- **1.0**: Nature, Science, NEJM
- **0.8**: Journals de alta calidad
- **0.6**: Medios especializados confiables
- **0.4**: Fuentes acad√©micas est√°ndar

#### ‚è∞ Recencia (20%)
- **1.0**: Publicado en la √∫ltima hora
- **0.9**: Publicado hoy
- **0.7**: Publicado esta semana
- **0.3**: Publicado este mes

#### üìù Calidad de Contenido (25%)
- Longitud apropiada del texto
- Presencia de terminolog√≠a cient√≠fica
- Estructura del t√≠tulo
- Diversidad de vocabulario

#### üî• Potencial de Engagement (30%)
- Palabras que indican descubrimientos importantes
- Temas trending en ciencia
- Accesibilidad para audiencia general
- "Factor wow" del contenido

### Interpretando Resultados

```
Score >= 0.8  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  Excelente - Art√≠culo destacado
Score >= 0.6  ‚≠ê‚≠ê‚≠ê‚≠ê    Muy bueno - Alta relevancia
Score >= 0.4  ‚≠ê‚≠ê‚≠ê      Bueno - Relevante
Score >= 0.2  ‚≠ê‚≠ê        Regular - Consideraci√≥n
Score <  0.2  ‚≠ê          Bajo - Probablemente descartado
```

---

## üìÅ Estructura del Proyecto

```
news_collector/
‚îú‚îÄ‚îÄ main.py                 # Orquestador principal
‚îú‚îÄ‚îÄ run_collector.py        # Script de ejecuci√≥n simple
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias Python
‚îú‚îÄ‚îÄ .env.example           # Configuraci√≥n de ejemplo
‚îÇ
‚îú‚îÄ‚îÄ config/                # Configuraci√≥n del sistema
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py        # Configuraci√≥n general
‚îÇ   ‚îî‚îÄ‚îÄ sources.py         # Cat√°logo de fuentes RSS
‚îÇ
‚îú‚îÄ‚îÄ src/                   # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ collectors/        # Sistemas de recolecci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_collector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rss_collector.py
‚îÇ   ‚îú‚îÄ‚îÄ scoring/           # Sistema de scoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basic_scorer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_scorer.py
‚îÇ   ‚îú‚îÄ‚îÄ reranker/          # Capa determin√≠stica de reordenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reranker.py
‚îÇ   ‚îú‚îÄ‚îÄ storage/           # Persistencia de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îî‚îÄ‚îÄ data/                  # Datos del sistema
    ‚îú‚îÄ‚îÄ news.db           # Base de datos SQLite
    ‚îî‚îÄ‚îÄ logs/             # Archivos de log
```

---

## üîç Debugging y Troubleshooting

### Problemas Comunes

#### Error de Dependencias
```bash
# Verificar que todas las dependencias est√©n instaladas
python run_collector.py --check-deps

# Reinstalar dependencias
python -m pip install --require-hashes -r requirements.lock
```

#### Problemas de Red
```bash
# Aumentar timeout en .env
REQUEST_TIMEOUT=60
REQUEST_DELAY=2.0

# Verificar conectividad
ping www.nature.com
```

#### Base de Datos Corrupta
```bash
# Eliminar y recrear base de datos
rm data/news.db
python run_collector.py --dry-run  # Recrear√° la DB
```

### Modo Debug

```bash
# Activar logging detallado
export DEBUG=true
export LOG_LEVEL=DEBUG
python run_collector.py --verbose
```

### Logs √ötiles

```bash
# Ver logs en tiempo real
tail -f data/logs/collector.log

# Buscar errores espec√≠ficos
grep "ERROR" data/logs/collector.log

# Ver estad√≠sticas de fuentes
grep "Art√≠culo guardado" data/logs/collector.log | wc -l
```

---

## üöÄ Optimizaci√≥n y Performance

### Para Vol√∫menes Altos

1. **Usar PostgreSQL**:
```bash
# En .env
DB_TYPE=postgresql
DB_HOST=localhost
DB_NAME=news_collector
DB_USER=collector
DB_PASSWORD=secure_password
```

2. **Ajustar Paralelismo**:
```bash
# Reducir delay entre requests
REQUEST_DELAY=0.5

# Aumentar l√≠mite por fuente
MAX_ARTICLES_PER_SOURCE=100
```

3. **Optimizar Scoring**:
```bash
# Ser m√°s selectivo
MINIMUM_SCORE=0.5
DAILY_TOP_COUNT=15
```

### Monitoreo

```python
# Obtener m√©tricas de performance
stats = system.get_system_statistics()
print(f"Art√≠culos procesados: {stats['daily_statistics']['articles_processed']}")
print(f"Tasa de √©xito: {stats['database_health']['status']}")
```

---

## üîÆ Roadmap Futuro

### Versi√≥n 1.1 - Mejoras de Core
- [ ] Procesamiento paralelo de fuentes
- [ ] Cache inteligente para evitar re-processing
- [ ] API REST para acceso externo
- [ ] Dashboard web para monitoreo

### Versi√≥n 1.2 - ML Avanzado
- [ ] Modelos de ML para scoring mejorado
- [ ] An√°lisis de sentimientos
- [ ] Detecci√≥n de temas trending autom√°tica
- [ ] Personalizaci√≥n basada en feedback

### Versi√≥n 1.3 - Integraci√≥n
- [ ] Webhooks para notificaciones
- [ ] Integraci√≥n con redes sociales
- [ ] Export a diferentes formatos (JSON, RSS, email)
- [ ] Slack/Discord bots

### Versi√≥n 2.0 - Escalabilidad
- [ ] Arquitectura distribuida
- [ ] Queue systems (Redis/RabbitMQ)
- [ ] Multi-idioma support
- [ ] Cloud deployment autom√°tico

---

## ü§ù Contribuir

¬°Las contribuciones son bienvenidas! Aqu√≠'s c√≥mo puedes ayudar:

### Reportar Issues
- Usa el template de issue en GitHub
- Incluye logs relevantes
- Describe pasos para reproducir

### Agregar Fuentes
1. Edita `config/sources.py`
2. Agrega tu fuente con metadata completa
3. Testea con `--sources tu_fuente --dry-run`
4. Crea Pull Request

### Mejorar Scoring
1. Modifica `src/scoring/feature_scorer.py` (o `basic_scorer.py` si trabajas en el modo legacy).
2. Ejecuta `python scripts/evaluate_ranking.py` y `python scripts/enrichment_sanity.py`.
3. Agrega/actualiza tests (golden set en `tests/test_enrichment_pipeline.py`).
4. Documenta los cambios en este README y abre un Pull Request.

---

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para detalles.

---

## üôè Agradecimientos

- **Fuentes de Datos**: Gracias a todas las instituciones cient√≠ficas que proporcionan feeds RSS p√∫blicos
- **Bibliotecas Open Source**: feedparser, requests, SQLAlchemy, loguru, y muchas otras
- **Comunidad Cient√≠fica**: Por hacer la informaci√≥n accesible y verificable

---

## üìû Soporte

- **Issues**: [GitHub Issues](https://github.com/cortega26/news-collector/issues)
- **Discusiones**: [GitHub Discussions](https://github.com/cortega26/news-collector/discussions)
- **Email**: n/a

---

## üèÜ Stats del Proyecto

- **üî¨ Fuentes Monitoreadas**: 15+ fuentes premium
- **‚ö° Velocidad**: ~10-50 art√≠culos/segundo
- **üéØ Precisi√≥n**: Score accuracy >85%
- **üõ°Ô∏è Disponibilidad**: 99.9% uptime
- **üìä Procesamiento**: ~1000+ art√≠culos/d√≠a

---

*Construido con ‚ù§Ô∏è para la comunidad cient√≠fica hispanohablante*
